{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60283c0b-0067-48ad-9fa4-734458d56d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e879aa-38c9-4c60-a6ae-01601c85256d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>GDP/capita growth (%)</th>\n",
       "      <th>Access to electricity</th>\n",
       "      <th>Literacy rate (adult female)</th>\n",
       "      <th>Literacy rate (youth female)</th>\n",
       "      <th>Literacy rate (youth male)</th>\n",
       "      <th>Literacy rate (adult male)</th>\n",
       "      <th>Life expectancy at birth (female)</th>\n",
       "      <th>Life expectancy at birth (\\male)</th>\n",
       "      <th>Primary school enrollment (net%)</th>\n",
       "      <th>Labor force participation rate (female%)</th>\n",
       "      <th>Labor force participation rate (male%)</th>\n",
       "      <th>Net migration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>2.357339</td>\n",
       "      <td>89.318225</td>\n",
       "      <td>85.145782</td>\n",
       "      <td>93.649338</td>\n",
       "      <td>91.902779</td>\n",
       "      <td>87.969719</td>\n",
       "      <td>72.065137</td>\n",
       "      <td>65.750388</td>\n",
       "      <td>91.702070</td>\n",
       "      <td>40.455670</td>\n",
       "      <td>71.564291</td>\n",
       "      <td>-799413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994</td>\n",
       "      <td>3.575111</td>\n",
       "      <td>90.223083</td>\n",
       "      <td>85.700523</td>\n",
       "      <td>94.091949</td>\n",
       "      <td>92.659912</td>\n",
       "      <td>88.555008</td>\n",
       "      <td>72.408284</td>\n",
       "      <td>66.149040</td>\n",
       "      <td>91.175760</td>\n",
       "      <td>41.652467</td>\n",
       "      <td>71.242033</td>\n",
       "      <td>-727304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>-0.841473</td>\n",
       "      <td>88.599506</td>\n",
       "      <td>86.312340</td>\n",
       "      <td>94.521599</td>\n",
       "      <td>93.420387</td>\n",
       "      <td>88.824631</td>\n",
       "      <td>72.754166</td>\n",
       "      <td>66.425347</td>\n",
       "      <td>91.075740</td>\n",
       "      <td>42.849265</td>\n",
       "      <td>70.919774</td>\n",
       "      <td>-812708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996</td>\n",
       "      <td>2.367651</td>\n",
       "      <td>89.557909</td>\n",
       "      <td>86.693207</td>\n",
       "      <td>94.821121</td>\n",
       "      <td>93.742462</td>\n",
       "      <td>89.099770</td>\n",
       "      <td>73.117666</td>\n",
       "      <td>66.802275</td>\n",
       "      <td>91.551620</td>\n",
       "      <td>42.556270</td>\n",
       "      <td>69.970452</td>\n",
       "      <td>-814722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>3.620615</td>\n",
       "      <td>90.015864</td>\n",
       "      <td>86.990997</td>\n",
       "      <td>94.866676</td>\n",
       "      <td>93.907623</td>\n",
       "      <td>89.505096</td>\n",
       "      <td>73.483913</td>\n",
       "      <td>67.154166</td>\n",
       "      <td>90.591650</td>\n",
       "      <td>43.339769</td>\n",
       "      <td>69.828303</td>\n",
       "      <td>-802462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998</td>\n",
       "      <td>1.059776</td>\n",
       "      <td>90.636887</td>\n",
       "      <td>87.535812</td>\n",
       "      <td>95.135422</td>\n",
       "      <td>94.211693</td>\n",
       "      <td>89.744217</td>\n",
       "      <td>73.701137</td>\n",
       "      <td>67.433797</td>\n",
       "      <td>92.100535</td>\n",
       "      <td>43.640127</td>\n",
       "      <td>69.902232</td>\n",
       "      <td>-798462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1999</td>\n",
       "      <td>-0.865684</td>\n",
       "      <td>91.247588</td>\n",
       "      <td>87.886726</td>\n",
       "      <td>95.358742</td>\n",
       "      <td>94.382912</td>\n",
       "      <td>89.914337</td>\n",
       "      <td>74.114224</td>\n",
       "      <td>67.825597</td>\n",
       "      <td>93.609420</td>\n",
       "      <td>44.277077</td>\n",
       "      <td>69.962526</td>\n",
       "      <td>-870278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2.058134</td>\n",
       "      <td>91.725741</td>\n",
       "      <td>88.205704</td>\n",
       "      <td>95.574059</td>\n",
       "      <td>94.570038</td>\n",
       "      <td>90.085747</td>\n",
       "      <td>74.563693</td>\n",
       "      <td>68.032323</td>\n",
       "      <td>94.227670</td>\n",
       "      <td>44.399940</td>\n",
       "      <td>69.168548</td>\n",
       "      <td>-933168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.919453</td>\n",
       "      <td>92.342229</td>\n",
       "      <td>88.230637</td>\n",
       "      <td>95.670761</td>\n",
       "      <td>94.702438</td>\n",
       "      <td>90.132202</td>\n",
       "      <td>74.842232</td>\n",
       "      <td>68.273577</td>\n",
       "      <td>94.465920</td>\n",
       "      <td>44.522803</td>\n",
       "      <td>68.374571</td>\n",
       "      <td>-949876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2002</td>\n",
       "      <td>-0.832495</td>\n",
       "      <td>92.646073</td>\n",
       "      <td>88.410057</td>\n",
       "      <td>95.978668</td>\n",
       "      <td>95.125069</td>\n",
       "      <td>90.849586</td>\n",
       "      <td>75.167799</td>\n",
       "      <td>68.639360</td>\n",
       "      <td>94.293610</td>\n",
       "      <td>46.116231</td>\n",
       "      <td>68.819754</td>\n",
       "      <td>-947054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2003</td>\n",
       "      <td>1.216159</td>\n",
       "      <td>92.739120</td>\n",
       "      <td>89.211067</td>\n",
       "      <td>96.626022</td>\n",
       "      <td>95.949471</td>\n",
       "      <td>90.809792</td>\n",
       "      <td>75.266017</td>\n",
       "      <td>68.893486</td>\n",
       "      <td>93.671960</td>\n",
       "      <td>45.209096</td>\n",
       "      <td>67.893652</td>\n",
       "      <td>-1001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004</td>\n",
       "      <td>4.257426</td>\n",
       "      <td>93.226985</td>\n",
       "      <td>89.220299</td>\n",
       "      <td>96.830879</td>\n",
       "      <td>96.033501</td>\n",
       "      <td>91.245880</td>\n",
       "      <td>75.596948</td>\n",
       "      <td>69.202567</td>\n",
       "      <td>93.978110</td>\n",
       "      <td>45.366216</td>\n",
       "      <td>66.989074</td>\n",
       "      <td>-922857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2005</td>\n",
       "      <td>2.731720</td>\n",
       "      <td>93.553600</td>\n",
       "      <td>89.740631</td>\n",
       "      <td>97.032257</td>\n",
       "      <td>96.244888</td>\n",
       "      <td>91.327278</td>\n",
       "      <td>75.925284</td>\n",
       "      <td>69.600113</td>\n",
       "      <td>94.170770</td>\n",
       "      <td>45.056885</td>\n",
       "      <td>65.667598</td>\n",
       "      <td>-1043018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2006</td>\n",
       "      <td>3.812768</td>\n",
       "      <td>94.268651</td>\n",
       "      <td>89.554871</td>\n",
       "      <td>96.964241</td>\n",
       "      <td>96.511749</td>\n",
       "      <td>91.834633</td>\n",
       "      <td>76.129083</td>\n",
       "      <td>69.810083</td>\n",
       "      <td>93.946260</td>\n",
       "      <td>44.879239</td>\n",
       "      <td>66.776375</td>\n",
       "      <td>-1021265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007</td>\n",
       "      <td>4.078821</td>\n",
       "      <td>94.496909</td>\n",
       "      <td>90.341614</td>\n",
       "      <td>97.279984</td>\n",
       "      <td>96.773560</td>\n",
       "      <td>92.066933</td>\n",
       "      <td>76.264674</td>\n",
       "      <td>69.954385</td>\n",
       "      <td>93.698690</td>\n",
       "      <td>44.413614</td>\n",
       "      <td>65.142829</td>\n",
       "      <td>-998162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008</td>\n",
       "      <td>2.574894</td>\n",
       "      <td>95.230451</td>\n",
       "      <td>90.596832</td>\n",
       "      <td>97.409698</td>\n",
       "      <td>96.934471</td>\n",
       "      <td>92.340660</td>\n",
       "      <td>76.467081</td>\n",
       "      <td>70.187107</td>\n",
       "      <td>95.073210</td>\n",
       "      <td>43.824314</td>\n",
       "      <td>64.031374</td>\n",
       "      <td>-1032747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2009</td>\n",
       "      <td>-3.060060</td>\n",
       "      <td>95.379750</td>\n",
       "      <td>90.863998</td>\n",
       "      <td>97.665359</td>\n",
       "      <td>97.257004</td>\n",
       "      <td>92.152687</td>\n",
       "      <td>76.643749</td>\n",
       "      <td>70.409267</td>\n",
       "      <td>94.868600</td>\n",
       "      <td>43.756255</td>\n",
       "      <td>64.034395</td>\n",
       "      <td>-958488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010</td>\n",
       "      <td>5.318462</td>\n",
       "      <td>95.852776</td>\n",
       "      <td>91.011017</td>\n",
       "      <td>97.657249</td>\n",
       "      <td>97.036568</td>\n",
       "      <td>92.752312</td>\n",
       "      <td>76.521552</td>\n",
       "      <td>70.318719</td>\n",
       "      <td>94.926300</td>\n",
       "      <td>42.723667</td>\n",
       "      <td>63.098944</td>\n",
       "      <td>-590240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011</td>\n",
       "      <td>3.284794</td>\n",
       "      <td>96.184007</td>\n",
       "      <td>91.550621</td>\n",
       "      <td>98.033684</td>\n",
       "      <td>97.483841</td>\n",
       "      <td>92.880127</td>\n",
       "      <td>77.001167</td>\n",
       "      <td>70.803219</td>\n",
       "      <td>94.775540</td>\n",
       "      <td>41.691078</td>\n",
       "      <td>62.163493</td>\n",
       "      <td>-495889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.441359</td>\n",
       "      <td>96.564340</td>\n",
       "      <td>91.861923</td>\n",
       "      <td>98.170029</td>\n",
       "      <td>97.685303</td>\n",
       "      <td>92.900192</td>\n",
       "      <td>77.249930</td>\n",
       "      <td>71.009666</td>\n",
       "      <td>94.845270</td>\n",
       "      <td>41.047305</td>\n",
       "      <td>61.672130</td>\n",
       "      <td>-488483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.755531</td>\n",
       "      <td>96.842328</td>\n",
       "      <td>91.933929</td>\n",
       "      <td>98.133308</td>\n",
       "      <td>97.657173</td>\n",
       "      <td>93.306801</td>\n",
       "      <td>77.440365</td>\n",
       "      <td>71.306331</td>\n",
       "      <td>93.663060</td>\n",
       "      <td>40.859926</td>\n",
       "      <td>60.793181</td>\n",
       "      <td>-535370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.331617</td>\n",
       "      <td>97.032812</td>\n",
       "      <td>92.414940</td>\n",
       "      <td>98.426788</td>\n",
       "      <td>98.017380</td>\n",
       "      <td>93.518242</td>\n",
       "      <td>77.604605</td>\n",
       "      <td>71.542654</td>\n",
       "      <td>93.479570</td>\n",
       "      <td>40.093097</td>\n",
       "      <td>60.367857</td>\n",
       "      <td>-494419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015</td>\n",
       "      <td>-0.502262</td>\n",
       "      <td>97.285034</td>\n",
       "      <td>92.550301</td>\n",
       "      <td>98.487091</td>\n",
       "      <td>98.072166</td>\n",
       "      <td>93.988007</td>\n",
       "      <td>77.717340</td>\n",
       "      <td>71.562013</td>\n",
       "      <td>93.402400</td>\n",
       "      <td>40.582457</td>\n",
       "      <td>60.663983</td>\n",
       "      <td>-424043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016</td>\n",
       "      <td>-1.161148</td>\n",
       "      <td>97.487192</td>\n",
       "      <td>93.014267</td>\n",
       "      <td>98.617188</td>\n",
       "      <td>98.196960</td>\n",
       "      <td>94.007431</td>\n",
       "      <td>77.767571</td>\n",
       "      <td>71.462842</td>\n",
       "      <td>93.583510</td>\n",
       "      <td>40.139043</td>\n",
       "      <td>59.162461</td>\n",
       "      <td>-139806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.893341</td>\n",
       "      <td>97.733595</td>\n",
       "      <td>93.072502</td>\n",
       "      <td>98.582748</td>\n",
       "      <td>98.217018</td>\n",
       "      <td>94.114647</td>\n",
       "      <td>77.832157</td>\n",
       "      <td>71.685650</td>\n",
       "      <td>93.653730</td>\n",
       "      <td>40.331597</td>\n",
       "      <td>58.866526</td>\n",
       "      <td>-281608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.703677</td>\n",
       "      <td>97.802699</td>\n",
       "      <td>93.269257</td>\n",
       "      <td>98.653458</td>\n",
       "      <td>98.304230</td>\n",
       "      <td>94.516350</td>\n",
       "      <td>77.975694</td>\n",
       "      <td>71.780270</td>\n",
       "      <td>93.716610</td>\n",
       "      <td>41.278128</td>\n",
       "      <td>59.198791</td>\n",
       "      <td>-338149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.150346</td>\n",
       "      <td>98.091935</td>\n",
       "      <td>93.693878</td>\n",
       "      <td>98.687698</td>\n",
       "      <td>98.341942</td>\n",
       "      <td>94.537781</td>\n",
       "      <td>78.175604</td>\n",
       "      <td>71.954692</td>\n",
       "      <td>93.716610</td>\n",
       "      <td>41.902703</td>\n",
       "      <td>59.261798</td>\n",
       "      <td>-424522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time  GDP/capita growth (%)  Access to electricity  \\\n",
       "0   1993               2.357339              89.318225   \n",
       "1   1994               3.575111              90.223083   \n",
       "2   1995              -0.841473              88.599506   \n",
       "3   1996               2.367651              89.557909   \n",
       "4   1997               3.620615              90.015864   \n",
       "5   1998               1.059776              90.636887   \n",
       "6   1999              -0.865684              91.247588   \n",
       "7   2000               2.058134              91.725741   \n",
       "8   2001              -0.919453              92.342229   \n",
       "9   2002              -0.832495              92.646073   \n",
       "10  2003               1.216159              92.739120   \n",
       "11  2004               4.257426              93.226985   \n",
       "12  2005               2.731720              93.553600   \n",
       "13  2006               3.812768              94.268651   \n",
       "14  2007               4.078821              94.496909   \n",
       "15  2008               2.574894              95.230451   \n",
       "16  2009              -3.060060              95.379750   \n",
       "17  2010               5.318462              95.852776   \n",
       "18  2011               3.284794              96.184007   \n",
       "19  2012               1.441359              96.564340   \n",
       "20  2013               1.755531              96.842328   \n",
       "21  2014               0.331617              97.032812   \n",
       "22  2015              -0.502262              97.285034   \n",
       "23  2016              -1.161148              97.487192   \n",
       "24  2017               0.893341              97.733595   \n",
       "25  2018               0.703677              97.802699   \n",
       "26  2019              -0.150346              98.091935   \n",
       "\n",
       "    Literacy rate (adult female)  Literacy rate (youth female)  \\\n",
       "0                      85.145782                     93.649338   \n",
       "1                      85.700523                     94.091949   \n",
       "2                      86.312340                     94.521599   \n",
       "3                      86.693207                     94.821121   \n",
       "4                      86.990997                     94.866676   \n",
       "5                      87.535812                     95.135422   \n",
       "6                      87.886726                     95.358742   \n",
       "7                      88.205704                     95.574059   \n",
       "8                      88.230637                     95.670761   \n",
       "9                      88.410057                     95.978668   \n",
       "10                     89.211067                     96.626022   \n",
       "11                     89.220299                     96.830879   \n",
       "12                     89.740631                     97.032257   \n",
       "13                     89.554871                     96.964241   \n",
       "14                     90.341614                     97.279984   \n",
       "15                     90.596832                     97.409698   \n",
       "16                     90.863998                     97.665359   \n",
       "17                     91.011017                     97.657249   \n",
       "18                     91.550621                     98.033684   \n",
       "19                     91.861923                     98.170029   \n",
       "20                     91.933929                     98.133308   \n",
       "21                     92.414940                     98.426788   \n",
       "22                     92.550301                     98.487091   \n",
       "23                     93.014267                     98.617188   \n",
       "24                     93.072502                     98.582748   \n",
       "25                     93.269257                     98.653458   \n",
       "26                     93.693878                     98.687698   \n",
       "\n",
       "    Literacy rate (youth male)  Literacy rate (adult male)  \\\n",
       "0                    91.902779                   87.969719   \n",
       "1                    92.659912                   88.555008   \n",
       "2                    93.420387                   88.824631   \n",
       "3                    93.742462                   89.099770   \n",
       "4                    93.907623                   89.505096   \n",
       "5                    94.211693                   89.744217   \n",
       "6                    94.382912                   89.914337   \n",
       "7                    94.570038                   90.085747   \n",
       "8                    94.702438                   90.132202   \n",
       "9                    95.125069                   90.849586   \n",
       "10                   95.949471                   90.809792   \n",
       "11                   96.033501                   91.245880   \n",
       "12                   96.244888                   91.327278   \n",
       "13                   96.511749                   91.834633   \n",
       "14                   96.773560                   92.066933   \n",
       "15                   96.934471                   92.340660   \n",
       "16                   97.257004                   92.152687   \n",
       "17                   97.036568                   92.752312   \n",
       "18                   97.483841                   92.880127   \n",
       "19                   97.685303                   92.900192   \n",
       "20                   97.657173                   93.306801   \n",
       "21                   98.017380                   93.518242   \n",
       "22                   98.072166                   93.988007   \n",
       "23                   98.196960                   94.007431   \n",
       "24                   98.217018                   94.114647   \n",
       "25                   98.304230                   94.516350   \n",
       "26                   98.341942                   94.537781   \n",
       "\n",
       "    Life expectancy at birth (female)  Life expectancy at birth (\\male)  \\\n",
       "0                           72.065137                         65.750388   \n",
       "1                           72.408284                         66.149040   \n",
       "2                           72.754166                         66.425347   \n",
       "3                           73.117666                         66.802275   \n",
       "4                           73.483913                         67.154166   \n",
       "5                           73.701137                         67.433797   \n",
       "6                           74.114224                         67.825597   \n",
       "7                           74.563693                         68.032323   \n",
       "8                           74.842232                         68.273577   \n",
       "9                           75.167799                         68.639360   \n",
       "10                          75.266017                         68.893486   \n",
       "11                          75.596948                         69.202567   \n",
       "12                          75.925284                         69.600113   \n",
       "13                          76.129083                         69.810083   \n",
       "14                          76.264674                         69.954385   \n",
       "15                          76.467081                         70.187107   \n",
       "16                          76.643749                         70.409267   \n",
       "17                          76.521552                         70.318719   \n",
       "18                          77.001167                         70.803219   \n",
       "19                          77.249930                         71.009666   \n",
       "20                          77.440365                         71.306331   \n",
       "21                          77.604605                         71.542654   \n",
       "22                          77.717340                         71.562013   \n",
       "23                          77.767571                         71.462842   \n",
       "24                          77.832157                         71.685650   \n",
       "25                          77.975694                         71.780270   \n",
       "26                          78.175604                         71.954692   \n",
       "\n",
       "    Primary school enrollment (net%)  \\\n",
       "0                          91.702070   \n",
       "1                          91.175760   \n",
       "2                          91.075740   \n",
       "3                          91.551620   \n",
       "4                          90.591650   \n",
       "5                          92.100535   \n",
       "6                          93.609420   \n",
       "7                          94.227670   \n",
       "8                          94.465920   \n",
       "9                          94.293610   \n",
       "10                         93.671960   \n",
       "11                         93.978110   \n",
       "12                         94.170770   \n",
       "13                         93.946260   \n",
       "14                         93.698690   \n",
       "15                         95.073210   \n",
       "16                         94.868600   \n",
       "17                         94.926300   \n",
       "18                         94.775540   \n",
       "19                         94.845270   \n",
       "20                         93.663060   \n",
       "21                         93.479570   \n",
       "22                         93.402400   \n",
       "23                         93.583510   \n",
       "24                         93.653730   \n",
       "25                         93.716610   \n",
       "26                         93.716610   \n",
       "\n",
       "    Labor force participation rate (female%)  \\\n",
       "0                                  40.455670   \n",
       "1                                  41.652467   \n",
       "2                                  42.849265   \n",
       "3                                  42.556270   \n",
       "4                                  43.339769   \n",
       "5                                  43.640127   \n",
       "6                                  44.277077   \n",
       "7                                  44.399940   \n",
       "8                                  44.522803   \n",
       "9                                  46.116231   \n",
       "10                                 45.209096   \n",
       "11                                 45.366216   \n",
       "12                                 45.056885   \n",
       "13                                 44.879239   \n",
       "14                                 44.413614   \n",
       "15                                 43.824314   \n",
       "16                                 43.756255   \n",
       "17                                 42.723667   \n",
       "18                                 41.691078   \n",
       "19                                 41.047305   \n",
       "20                                 40.859926   \n",
       "21                                 40.093097   \n",
       "22                                 40.582457   \n",
       "23                                 40.139043   \n",
       "24                                 40.331597   \n",
       "25                                 41.278128   \n",
       "26                                 41.902703   \n",
       "\n",
       "    Labor force participation rate (male%)  Net migration  \n",
       "0                                71.564291        -799413  \n",
       "1                                71.242033        -727304  \n",
       "2                                70.919774        -812708  \n",
       "3                                69.970452        -814722  \n",
       "4                                69.828303        -802462  \n",
       "5                                69.902232        -798462  \n",
       "6                                69.962526        -870278  \n",
       "7                                69.168548        -933168  \n",
       "8                                68.374571        -949876  \n",
       "9                                68.819754        -947054  \n",
       "10                               67.893652       -1001536  \n",
       "11                               66.989074        -922857  \n",
       "12                               65.667598       -1043018  \n",
       "13                               66.776375       -1021265  \n",
       "14                               65.142829        -998162  \n",
       "15                               64.031374       -1032747  \n",
       "16                               64.034395        -958488  \n",
       "17                               63.098944        -590240  \n",
       "18                               62.163493        -495889  \n",
       "19                               61.672130        -488483  \n",
       "20                               60.793181        -535370  \n",
       "21                               60.367857        -494419  \n",
       "22                               60.663983        -424043  \n",
       "23                               59.162461        -139806  \n",
       "24                               58.866526        -281608  \n",
       "25                               59.198791        -338149  \n",
       "26                               59.261798        -424522  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ_df = pd.read_csv(\n",
    "    \"Resources/Refined Data Set.csv\"\n",
    ")\n",
    "\n",
    "econ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1c34b9-ec8f-476c-9a15-6b414cd273de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the X and y sets\n",
    "y = econ_df[\"GDP/capita growth (%)\"]\n",
    "X = econ_df.drop(columns=[\"GDP/capita growth (%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838e445e-de32-4593-a069-55a65c608e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into traning and testing sets using the train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c1fd34-84a7-4817-9d89-dff1032b69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9076160-a51a-4a8e-88e7-fa64de035d3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: 'sigmod'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m nn\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39mhidden_nodes_l2, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# nn1.add(Dense(units=hidden_nodes_l3, activation=\"linear\"))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# output\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m nn\u001b[38;5;241m.\u001b[39madd(\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msigmod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras\\dtensor\\utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[0;32m     94\u001b[0m             layout_args[variable_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_layout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layout\n\u001b[1;32m---> 96\u001b[0m init_method(layer_instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layout_param_name, layout \u001b[38;5;129;01min\u001b[39;00m layout_args\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras\\layers\\core\\dense.py:125\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived an invalid value for `units`, expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma positive integer. Received: units=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m     )\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer)\n",
      "File \u001b[1;32m~\\anaconda4\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras\\activations.py:609\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m linear\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(identifier, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m--> 609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m callable(identifier):\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m identifier\n",
      "File \u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras\\activations.py:568\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# we put 'current_module' after 'activation_layers' to prefer the local one\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# if there is a collision\u001b[39;00m\n\u001b[0;32m    562\u001b[0m generic_utils\u001b[38;5;241m.\u001b[39mpopulate_dict_with_module_objects(\n\u001b[0;32m    563\u001b[0m     activation_functions,\n\u001b[0;32m    564\u001b[0m     (activation_layers, current_module),\n\u001b[0;32m    565\u001b[0m     obj_filter\u001b[38;5;241m=\u001b[39mcallable,\n\u001b[0;32m    566\u001b[0m )\n\u001b[1;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactivation function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py:557\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    555\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure you are using a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.utils.custom_object_scope` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand that this object is included in the scope. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         )\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown activation function: 'sigmod'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "#instantiate\n",
    "nn = Sequential()\n",
    "\n",
    "# Define the the number of inputs and layer nodes\n",
    "n_inputs = 12\n",
    "hidden_nodes_l1 = 144\n",
    "hidden_nodes_l2 = 24\n",
    "# hidden_nodes_l3 = 14\n",
    "\n",
    "\n",
    "# hidden layers \n",
    "nn.add(Dense(units=hidden_nodes_l1, input_dim=n_inputs, activation=\"linear\"))\n",
    "\n",
    "nn.add(Dense(units=hidden_nodes_l2, activation=\"linear\"))\n",
    "\n",
    "# nn1.add(Dense(units=hidden_nodes_l3, activation=\"linear\"))\n",
    "\n",
    "# output\n",
    "nn.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3246f62-e1b1-4058-bf19-0a67a92b1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f142c1-c1e2-40f3-a33e-b4eaeb3aa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "# nn1.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ed9fc-caee-4db7-93a2-4e61d1c99375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364630b-4724-4038-bbf8-f4c1c8d80ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using 100 epochs and the training data\n",
    "nn_model_1 = nn.fit(X_train_scaled, y_train, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57267781-795d-496a-828e-75ceef149bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train function\n",
    "plt.plot(nn_model_1.history[\"loss\"])\n",
    "plt.title(\"Loss Function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e5fbc-5713-463f-8960-6a5fd423a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43824d-0dbd-4457-b2ef-2ab2e0b22928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in JSON format\n",
    "nn_json = nn.to_json()\n",
    "\n",
    "# Define a relative path to save the model\n",
    "# The model should be saved with a .json file extension\n",
    "nn_json_path_1 = Path(\"Models/nn.json\")\n",
    "\n",
    "# Write the model to the the file \n",
    "with open(nn_json_path_1, \"w\") as json_file:\n",
    "    json_file.write(nn_json)\n",
    "\n",
    "# Define a relative path to save the model weights\n",
    "# The model weights should be saved with a .h5 file extension\n",
    "nn_h5_path_1 = \"Models/nn.h5\"\n",
    "\n",
    "# Save the weights to the file path\n",
    "nn.save_weights(nn_h5_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5eb73-ad9a-4c46-a3dc-70a8b756e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# Load the model to predict values\n",
    "# Identify the relative path of the model's location\n",
    "nn_json_path_2 = Path(\"Models/nn.json\")\n",
    "\n",
    "# Read in the model and save it as the variable loaded_model\n",
    "with open(nn_json_path_2, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "nn_model_2 = model_from_json(model_json)\n",
    "\n",
    "# Identify the relative path for the model's weights\n",
    "nn_h5_path_2 = \"Models/nn.h5\"\n",
    "\n",
    "# Load the model's weights to the variable loaded_model\n",
    "nn_model_2.load_weights(nn_h5_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c0b2c-34a2-4245-841e-37509cf1a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = nn1_model.predict(X_test_scaled)\n",
    "y_pred = nn_model_2.predict(X_test_scaled, verbose=0)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee816bc-b232-47d2-9b71-7e716f82d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    " \n",
    "r2 = r2_score(y_test, y_pred) \n",
    "mse = mean_squared_error(y_test, y_pred) \n",
    "rmse = np.sqrt(mse) \n",
    "std = np.std(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd20a3-62d8-4596-a7b5-227cc796d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The r2 is {r2}.\") \n",
    "print(f\"The mean squared error is {mse}.\") \n",
    "print(f\"The root mean squared error is {rmse}.\") \n",
    "print(f\"The standard deviation is {std}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
